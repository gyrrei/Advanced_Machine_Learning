{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Outliers detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Train/Test splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize\n",
    "\n",
    "# Neural networks\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "X = pd.read_csv('X_train.csv', float_precision='high').drop('id', axis=1)\n",
    "y = pd.read_csv('y_train.csv', float_precision='high').drop('id', axis=1)\n",
    "\n",
    "# replacing the missing values with the median of that column\n",
    "X = X.fillna(X.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "clf = IsolationForest(behaviour='new', max_samples=100, random_state = 1, contamination='auto')\n",
    "\n",
    "# getting the outliers\n",
    "preds = clf.fit_predict(X)\n",
    "\n",
    "# removing outliers\n",
    "X = X[preds==1]\n",
    "y = y[preds==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing features that correlate with label the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X.columns\n",
    "\n",
    "full_data = X.copy()\n",
    "full_data['y'] = y\n",
    "\n",
    "correlations = full_data.corr().y.dropna()\n",
    "\n",
    "# plotting the distribution of feature importance\n",
    "nbins = 50\n",
    "\n",
    "n, bins = np.histogram(correlations.values, nbins, density=1)\n",
    "\n",
    "pdfx, pdfy = np.zeros(n.size), np.zeros(n.size)\n",
    "\n",
    "for k in range(n.size):\n",
    "    pdfx[k], pdfy[k] = 0.5*(bins[k] + bins[k+1]), n[k]\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('distribution of correlations')\n",
    "plt.ylabel('no of occurencies')\n",
    "plt.xlabel('correlations')\n",
    "\n",
    "plt.plot(pdfx, pdfy, color = 'darkblue')\n",
    "plt.fill_between(pdfx, pdfy, color = 'lightblue')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "del full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the correlated features\n",
    "corr_features_1 = correlations[(abs(correlations) > 0.05) & (correlations.index != 'y')].index\n",
    "corr_features_2 = correlations[(abs(correlations) > 0.075) & (correlations.index != 'y')].index\n",
    "corr_features_3 = correlations[(abs(correlations) > 0.1) & (correlations.index != 'y')].index\n",
    "corr_features_4 = correlations[(abs(correlations) > 0.15) & (correlations.index != 'y')].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uni-variate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=10, score_func=<function f_regression at 0x1a171d6a70>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing the model\n",
    "bestfeatures = SelectKBest(score_func = f_regression)\n",
    "\n",
    "# fitting the model\n",
    "bestfeatures.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the best features\n",
    "uni_features_1 = features[bestfeatures.scores_ > 3.5] # rougly 250 features\n",
    "uni_features_2 = features[bestfeatures.scores_ > 10] # rougly 200 features\n",
    "uni_features_3 = features[bestfeatures.scores_ > 30] # rougly 150 features\n",
    "uni_features_4 = features[bestfeatures.scores_ > 50] # rougly 100 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=True, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing the model\n",
    "model = Lasso(alpha=1e-4, normalize=True)\n",
    "\n",
    "# fitting the model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_features_1 = features[(np.abs(model.coef_) > 1e-5)] # rougly 60 features\n",
    "lasso_features_2 = features[(np.abs(model.coef_) > 1e-6)] # rougly 80 features\n",
    "lasso_features_3 = features[(np.abs(model.coef_) > 0)] # rougly 100 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting The Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Normalizing the X values\n",
    "X_train_normalized = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_normalized = (X_test - X_test.mean()) / X_test.std()\n",
    "\n",
    "# Normalizing y values\n",
    "y_train_mean, y_train_std = y_train.mean()[0], y_train.std()[0]\n",
    "y_train_normalized = ((y_train - y_train_mean) / y_train_std).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(number_of_features):\n",
    "    model = Sequential([Dense(number_of_features, activation='relu'),\n",
    "                              Dense(1024, activation='relu'),\n",
    "                              Dense(512, activation='relu'),\n",
    "                              Dropout(0.1),\n",
    "                              Dense(1024, activation='relu'),\n",
    "                              Dense(1024, activation='relu'),\n",
    "                              Dropout(0.1),\n",
    "                              Dense(1024, activation='relu'),\n",
    "                              Dropout(0.1),\n",
    "                              Dense(512, activation='relu'),\n",
    "                              Dense(256, activation='relu'),\n",
    "                              Dense(1)])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 948 samples\n",
      "Epoch 1/30\n",
      "948/948 [==============================] - 2s 2ms/sample - loss: 0.7351\n",
      "Epoch 2/30\n",
      "948/948 [==============================] - 1s 897us/sample - loss: 0.5782\n",
      "Epoch 3/30\n",
      "948/948 [==============================] - 1s 843us/sample - loss: 0.5011\n",
      "Epoch 4/30\n",
      "948/948 [==============================] - 1s 823us/sample - loss: 0.4614\n",
      "Epoch 5/30\n",
      "948/948 [==============================] - 1s 828us/sample - loss: 0.4435\n",
      "Epoch 6/30\n",
      "948/948 [==============================] - 1s 857us/sample - loss: 0.3896\n",
      "Epoch 7/30\n",
      "948/948 [==============================] - 1s 843us/sample - loss: 0.3660\n",
      "Epoch 8/30\n",
      "948/948 [==============================] - 1s 995us/sample - loss: 0.3578\n",
      "Epoch 9/30\n",
      "948/948 [==============================] - 1s 839us/sample - loss: 0.3240\n",
      "Epoch 10/30\n",
      "948/948 [==============================] - 1s 848us/sample - loss: 0.2687\n",
      "Epoch 11/30\n",
      "948/948 [==============================] - 1s 855us/sample - loss: 0.2736\n",
      "Epoch 12/30\n",
      "948/948 [==============================] - 1s 849us/sample - loss: 0.2637\n",
      "Epoch 13/30\n",
      "948/948 [==============================] - 1s 814us/sample - loss: 0.2390\n",
      "Epoch 14/30\n",
      "948/948 [==============================] - 1s 803us/sample - loss: 0.2553\n",
      "Epoch 15/30\n",
      "948/948 [==============================] - 1s 821us/sample - loss: 0.2489\n",
      "Epoch 16/30\n",
      "948/948 [==============================] - 1s 839us/sample - loss: 0.2241\n",
      "Epoch 17/30\n",
      "948/948 [==============================] - 1s 831us/sample - loss: 0.2204\n",
      "Epoch 18/30\n",
      "948/948 [==============================] - 1s 828us/sample - loss: 0.2105\n",
      "Epoch 19/30\n",
      "948/948 [==============================] - 1s 886us/sample - loss: 0.2097\n",
      "Epoch 20/30\n",
      "948/948 [==============================] - 1s 877us/sample - loss: 0.1985\n",
      "Epoch 21/30\n",
      "948/948 [==============================] - 1s 959us/sample - loss: 0.2361\n",
      "Epoch 22/30\n",
      "948/948 [==============================] - 1s 881us/sample - loss: 0.2061\n",
      "Epoch 23/30\n",
      "948/948 [==============================] - 1s 811us/sample - loss: 0.1713\n",
      "Epoch 24/30\n",
      "948/948 [==============================] - 1s 775us/sample - loss: 0.1571\n",
      "Epoch 25/30\n",
      "948/948 [==============================] - 1s 770us/sample - loss: 0.1678\n",
      "Epoch 26/30\n",
      "948/948 [==============================] - 1s 773us/sample - loss: 0.1556\n",
      "Epoch 27/30\n",
      "948/948 [==============================] - 1s 779us/sample - loss: 0.1578\n",
      "Epoch 28/30\n",
      "948/948 [==============================] - 1s 775us/sample - loss: 0.1681\n",
      "Epoch 29/30\n",
      "948/948 [==============================] - 1s 777us/sample - loss: 0.1832\n",
      "Epoch 30/30\n",
      "948/948 [==============================] - 1s 774us/sample - loss: 0.1693\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 948 samples\n",
      "Epoch 1/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.6985\n",
      "Epoch 2/30\n",
      "948/948 [==============================] - 1s 719us/sample - loss: 0.5589\n",
      "Epoch 3/30\n",
      "948/948 [==============================] - 1s 718us/sample - loss: 0.5080\n",
      "Epoch 4/30\n",
      "948/948 [==============================] - 1s 725us/sample - loss: 0.4613\n",
      "Epoch 5/30\n",
      "948/948 [==============================] - 1s 736us/sample - loss: 0.4002\n",
      "Epoch 6/30\n",
      "948/948 [==============================] - 1s 824us/sample - loss: 0.3896\n",
      "Epoch 7/30\n",
      "948/948 [==============================] - 1s 728us/sample - loss: 0.4219\n",
      "Epoch 8/30\n",
      "948/948 [==============================] - 1s 752us/sample - loss: 0.3163\n",
      "Epoch 9/30\n",
      "948/948 [==============================] - 1s 759us/sample - loss: 0.3019\n",
      "Epoch 10/30\n",
      "948/948 [==============================] - 1s 754us/sample - loss: 0.2828\n",
      "Epoch 11/30\n",
      "948/948 [==============================] - 1s 758us/sample - loss: 0.2713\n",
      "Epoch 12/30\n",
      "948/948 [==============================] - 1s 761us/sample - loss: 0.2474\n",
      "Epoch 13/30\n",
      "948/948 [==============================] - 1s 760us/sample - loss: 0.2302\n",
      "Epoch 14/30\n",
      "948/948 [==============================] - 1s 767us/sample - loss: 0.2148\n",
      "Epoch 15/30\n",
      "948/948 [==============================] - 1s 777us/sample - loss: 0.2305\n",
      "Epoch 16/30\n",
      "948/948 [==============================] - 1s 774us/sample - loss: 0.2129\n",
      "Epoch 17/30\n",
      "948/948 [==============================] - 1s 770us/sample - loss: 0.2089\n",
      "Epoch 18/30\n",
      "948/948 [==============================] - 1s 778us/sample - loss: 0.1969\n",
      "Epoch 19/30\n",
      "948/948 [==============================] - 1s 783us/sample - loss: 0.1793\n",
      "Epoch 20/30\n",
      "948/948 [==============================] - 1s 777us/sample - loss: 0.1811\n",
      "Epoch 21/30\n",
      "948/948 [==============================] - 1s 831us/sample - loss: 0.1866\n",
      "Epoch 22/30\n",
      "948/948 [==============================] - 1s 771us/sample - loss: 0.2080\n",
      "Epoch 23/30\n",
      "948/948 [==============================] - 1s 779us/sample - loss: 0.1790\n",
      "Epoch 24/30\n",
      "948/948 [==============================] - 1s 799us/sample - loss: 0.1665\n",
      "Epoch 25/30\n",
      "948/948 [==============================] - 1s 791us/sample - loss: 0.1728\n",
      "Epoch 26/30\n",
      "948/948 [==============================] - 1s 800us/sample - loss: 0.1721\n",
      "Epoch 27/30\n",
      "948/948 [==============================] - 1s 825us/sample - loss: 0.1554\n",
      "Epoch 28/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.1640\n",
      "Epoch 29/30\n",
      "948/948 [==============================] - 1s 909us/sample - loss: 0.1577\n",
      "Epoch 30/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.1503\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 948 samples\n",
      "Epoch 1/30\n",
      "948/948 [==============================] - 1s 2ms/sample - loss: 0.7103\n",
      "Epoch 2/30\n",
      "948/948 [==============================] - 1s 946us/sample - loss: 0.5692\n",
      "Epoch 3/30\n",
      "948/948 [==============================] - 1s 925us/sample - loss: 0.4735\n",
      "Epoch 4/30\n",
      "948/948 [==============================] - 1s 939us/sample - loss: 0.4437\n",
      "Epoch 5/30\n",
      "948/948 [==============================] - 1s 983us/sample - loss: 0.3840\n",
      "Epoch 6/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.3778\n",
      "Epoch 7/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.3626\n",
      "Epoch 8/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.3134\n",
      "Epoch 9/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.2813\n",
      "Epoch 10/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.2709\n",
      "Epoch 11/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.2565\n",
      "Epoch 12/30\n",
      "948/948 [==============================] - 1s 912us/sample - loss: 0.2659\n",
      "Epoch 13/30\n",
      "948/948 [==============================] - 1s 931us/sample - loss: 0.2523\n",
      "Epoch 14/30\n",
      "948/948 [==============================] - 1s 914us/sample - loss: 0.2270\n",
      "Epoch 15/30\n",
      "948/948 [==============================] - 1s 918us/sample - loss: 0.2101\n",
      "Epoch 16/30\n",
      "948/948 [==============================] - 1s 881us/sample - loss: 0.2288\n",
      "Epoch 17/30\n",
      "948/948 [==============================] - 1s 884us/sample - loss: 0.2287\n",
      "Epoch 18/30\n",
      "948/948 [==============================] - 1s 937us/sample - loss: 0.2242\n",
      "Epoch 19/30\n",
      "948/948 [==============================] - 1s 885us/sample - loss: 0.1937\n",
      "Epoch 20/30\n",
      "948/948 [==============================] - 1s 910us/sample - loss: 0.2295\n",
      "Epoch 21/30\n",
      "948/948 [==============================] - 1s 971us/sample - loss: 0.2090\n",
      "Epoch 22/30\n",
      "948/948 [==============================] - 1s 952us/sample - loss: 0.2233\n",
      "Epoch 23/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.1707\n",
      "Epoch 24/30\n",
      "948/948 [==============================] - 1s 914us/sample - loss: 0.1734\n",
      "Epoch 25/30\n",
      "948/948 [==============================] - 1s 919us/sample - loss: 0.1728\n",
      "Epoch 26/30\n",
      "948/948 [==============================] - 1s 929us/sample - loss: 0.1817\n",
      "Epoch 27/30\n",
      "948/948 [==============================] - 1s 975us/sample - loss: 0.1599\n",
      "Epoch 28/30\n",
      "948/948 [==============================] - 1s 995us/sample - loss: 0.1519\n",
      "Epoch 29/30\n",
      "948/948 [==============================] - 1s 991us/sample - loss: 0.1693\n",
      "Epoch 30/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.1702\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 948 samples\n",
      "Epoch 1/30\n",
      "948/948 [==============================] - 2s 2ms/sample - loss: 0.6825\n",
      "Epoch 2/30\n",
      "948/948 [==============================] - 1s 901us/sample - loss: 0.5843\n",
      "Epoch 3/30\n",
      "948/948 [==============================] - 1s 948us/sample - loss: 0.5293\n",
      "Epoch 4/30\n",
      "948/948 [==============================] - 1s 868us/sample - loss: 0.4460\n",
      "Epoch 5/30\n",
      "948/948 [==============================] - 1s 868us/sample - loss: 0.4180\n",
      "Epoch 6/30\n",
      "948/948 [==============================] - 1s 870us/sample - loss: 0.3617\n",
      "Epoch 7/30\n",
      "948/948 [==============================] - 1s 928us/sample - loss: 0.3854\n",
      "Epoch 8/30\n",
      "948/948 [==============================] - 1s 997us/sample - loss: 0.3118\n",
      "Epoch 9/30\n",
      "948/948 [==============================] - 1s 883us/sample - loss: 0.3053\n",
      "Epoch 10/30\n",
      "948/948 [==============================] - 1s 933us/sample - loss: 0.2826\n",
      "Epoch 11/30\n",
      "948/948 [==============================] - 1s 927us/sample - loss: 0.2720\n",
      "Epoch 12/30\n",
      "948/948 [==============================] - 1s 898us/sample - loss: 0.2532\n",
      "Epoch 13/30\n",
      "948/948 [==============================] - 1s 952us/sample - loss: 0.2669\n",
      "Epoch 14/30\n",
      "948/948 [==============================] - 1s 977us/sample - loss: 0.2289\n",
      "Epoch 15/30\n",
      "948/948 [==============================] - 1s 2ms/sample - loss: 0.2237\n",
      "Epoch 16/30\n",
      "948/948 [==============================] - 1s 992us/sample - loss: 0.2241\n",
      "Epoch 17/30\n",
      "948/948 [==============================] - 1s 937us/sample - loss: 0.2022\n",
      "Epoch 18/30\n",
      "948/948 [==============================] - 1s 832us/sample - loss: 0.1873\n",
      "Epoch 19/30\n",
      "948/948 [==============================] - 1s 933us/sample - loss: 0.1996\n",
      "Epoch 20/30\n",
      "948/948 [==============================] - 1s 1ms/sample - loss: 0.2094\n",
      "Epoch 21/30\n",
      "948/948 [==============================] - 1s 867us/sample - loss: 0.2146\n",
      "Epoch 22/30\n",
      "948/948 [==============================] - 1s 836us/sample - loss: 0.1918\n",
      "Epoch 23/30\n",
      "948/948 [==============================] - 1s 833us/sample - loss: 0.1738\n",
      "Epoch 24/30\n",
      "948/948 [==============================] - 1s 919us/sample - loss: 0.1827\n",
      "Epoch 25/30\n",
      "948/948 [==============================] - 1s 934us/sample - loss: 0.1891\n",
      "Epoch 26/30\n",
      "948/948 [==============================] - 1s 949us/sample - loss: 0.1789\n",
      "Epoch 27/30\n",
      "948/948 [==============================] - 1s 923us/sample - loss: 0.1684\n",
      "Epoch 28/30\n",
      "948/948 [==============================] - 1s 867us/sample - loss: 0.1767\n",
      "Epoch 29/30\n",
      "948/948 [==============================] - 1s 983us/sample - loss: 0.1823\n",
      "Epoch 30/30\n",
      "948/948 [==============================] - 1s 857us/sample - loss: 0.1705\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "features_to_try = [corr_features_3, corr_features_4, uni_features_2, uni_features_3]\n",
    "\n",
    "scores, models, predictions = [],[],[]\n",
    "\n",
    "for features in features_to_try:\n",
    "    \n",
    "    # Choosing only the relevant features\n",
    "    X_train_relevant = X_train_normalized[features]\n",
    "    X_test_relevant = X_test_normalized[features]\n",
    "\n",
    "    # creating NN\n",
    "    model = create_network(number_of_features = X_train_relevant.shape[1])\n",
    "\n",
    "    # Fitting NN\n",
    "    model.fit(X_train_relevant.values, y_train_normalized, epochs = 30)\n",
    "\n",
    "    # Predicting values\n",
    "    y_pred = model.predict(X_test_relevant)\n",
    "    y_pred = y_pred * y_train_std + y_train_mean\n",
    "\n",
    "    # Saving the score\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "    # saving the model\n",
    "    models.append(model)\n",
    "\n",
    "    # saving the predictions\n",
    "    predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5764667080189876,\n",
       " 0.6244555876454709,\n",
       " 0.5618631481775186,\n",
       " 0.5169644558959626]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6446009748555783"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after boosting and trying all the possible combination the best result is:\n",
    "y_boosted = (predictions[0] + predictions[1] + predictions[2] + predictions[3]) / 4\n",
    "\n",
    "r2_score(y_test, y_boosted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40656129189624746,\n",
       " 0.36947915692252087,\n",
       " 0.36806156616814356,\n",
       " 0.4071637459427243]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45205338100356185"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after boosting and trying all the possible combination the best result is:\n",
    "y_boosted = (predictions[0] + predictions[1] + predictions[3]) / 3\n",
    "\n",
    "r2_score(y_test, y_boosted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5357304559358247,\n",
       " 0.47582900368011816,\n",
       " 0.5342105963499746,\n",
       " 0.5100096790440058]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5751679031001978"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after boosting and trying all the possible combination the best result is:\n",
    "y_boosted = (predictions[3] + predictions[0] + predictions[2] + predictions[1]) / 4\n",
    "\n",
    "r2_score(y_test, y_boosted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final model (built on the whole data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the X values\n",
    "X_normalized = (X - X.mean()) / X_train.std()\n",
    "\n",
    "# Normalizing y values\n",
    "y_mean, y_std = y.mean()[0], y.std()[0]\n",
    "y_normalized = ((y - y_mean) / y_std).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1185 samples\n",
      "Epoch 1/30\n",
      "1185/1185 [==============================] - 2s 1ms/sample - loss: 0.6908\n",
      "Epoch 2/30\n",
      "1185/1185 [==============================] - 1s 840us/sample - loss: 0.5835\n",
      "Epoch 3/30\n",
      "1185/1185 [==============================] - 1s 852us/sample - loss: 0.5151\n",
      "Epoch 4/30\n",
      "1185/1185 [==============================] - 1s 915us/sample - loss: 0.4734\n",
      "Epoch 5/30\n",
      "1185/1185 [==============================] - 1s 887us/sample - loss: 0.4303\n",
      "Epoch 6/30\n",
      "1185/1185 [==============================] - 1s 927us/sample - loss: 0.4284\n",
      "Epoch 7/30\n",
      "1185/1185 [==============================] - 1s 857us/sample - loss: 0.3489\n",
      "Epoch 8/30\n",
      "1185/1185 [==============================] - 1s 819us/sample - loss: 0.3691\n",
      "Epoch 9/30\n",
      "1185/1185 [==============================] - 1s 843us/sample - loss: 0.3805\n",
      "Epoch 10/30\n",
      "1185/1185 [==============================] - 1s 973us/sample - loss: 0.3511\n",
      "Epoch 11/30\n",
      "1185/1185 [==============================] - 1s 866us/sample - loss: 0.3193\n",
      "Epoch 12/30\n",
      "1185/1185 [==============================] - 1s 852us/sample - loss: 0.2943\n",
      "Epoch 13/30\n",
      "1185/1185 [==============================] - 1s 861us/sample - loss: 0.2938\n",
      "Epoch 14/30\n",
      "1185/1185 [==============================] - 1s 855us/sample - loss: 0.2850\n",
      "Epoch 15/30\n",
      "1185/1185 [==============================] - 1s 857us/sample - loss: 0.2686\n",
      "Epoch 16/30\n",
      "1185/1185 [==============================] - 1s 852us/sample - loss: 0.2394\n",
      "Epoch 17/30\n",
      "1185/1185 [==============================] - 1s 833us/sample - loss: 0.2181\n",
      "Epoch 18/30\n",
      "1185/1185 [==============================] - 1s 832us/sample - loss: 0.2077\n",
      "Epoch 19/30\n",
      "1185/1185 [==============================] - 1s 843us/sample - loss: 0.2486\n",
      "Epoch 20/30\n",
      "1185/1185 [==============================] - 1s 815us/sample - loss: 0.2063\n",
      "Epoch 21/30\n",
      "1185/1185 [==============================] - 1s 884us/sample - loss: 0.2267\n",
      "Epoch 22/30\n",
      "1185/1185 [==============================] - 1s 860us/sample - loss: 0.2210\n",
      "Epoch 23/30\n",
      "1185/1185 [==============================] - 1s 818us/sample - loss: 0.2141\n",
      "Epoch 24/30\n",
      "1185/1185 [==============================] - 1s 823us/sample - loss: 0.1939\n",
      "Epoch 25/30\n",
      "1185/1185 [==============================] - 1s 852us/sample - loss: 0.1995\n",
      "Epoch 26/30\n",
      "1185/1185 [==============================] - 1s 816us/sample - loss: 0.2363\n",
      "Epoch 27/30\n",
      "1185/1185 [==============================] - 1s 808us/sample - loss: 0.1804\n",
      "Epoch 28/30\n",
      "1185/1185 [==============================] - 1s 833us/sample - loss: 0.1885\n",
      "Epoch 29/30\n",
      "1185/1185 [==============================] - 1s 806us/sample - loss: 0.2175\n",
      "Epoch 30/30\n",
      "1185/1185 [==============================] - 1s 803us/sample - loss: 0.1751\n",
      "Train on 1185 samples\n",
      "Epoch 1/30\n",
      "1185/1185 [==============================] - 2s 2ms/sample - loss: 0.6863\n",
      "Epoch 2/30\n",
      "1185/1185 [==============================] - 1s 712us/sample - loss: 0.5735\n",
      "Epoch 3/30\n",
      "1185/1185 [==============================] - 1s 720us/sample - loss: 0.5516\n",
      "Epoch 4/30\n",
      "1185/1185 [==============================] - 1s 845us/sample - loss: 0.4898\n",
      "Epoch 5/30\n",
      "1185/1185 [==============================] - 1s 742us/sample - loss: 0.4811\n",
      "Epoch 6/30\n",
      "1185/1185 [==============================] - 1s 848us/sample - loss: 0.4102\n",
      "Epoch 7/30\n",
      "1185/1185 [==============================] - 1s 793us/sample - loss: 0.3625\n",
      "Epoch 8/30\n",
      "1185/1185 [==============================] - 1s 784us/sample - loss: 0.3405\n",
      "Epoch 9/30\n",
      "1185/1185 [==============================] - 1s 750us/sample - loss: 0.3637\n",
      "Epoch 10/30\n",
      "1185/1185 [==============================] - 1s 750us/sample - loss: 0.3791\n",
      "Epoch 11/30\n",
      "1185/1185 [==============================] - 1s 766us/sample - loss: 0.3396\n",
      "Epoch 12/30\n",
      "1185/1185 [==============================] - 1s 773us/sample - loss: 0.3536\n",
      "Epoch 13/30\n",
      "1185/1185 [==============================] - 1s 765us/sample - loss: 0.2991\n",
      "Epoch 14/30\n",
      "1185/1185 [==============================] - 1s 796us/sample - loss: 0.2839\n",
      "Epoch 15/30\n",
      "1185/1185 [==============================] - 1s 771us/sample - loss: 0.2583\n",
      "Epoch 16/30\n",
      "1185/1185 [==============================] - 1s 772us/sample - loss: 0.3554\n",
      "Epoch 17/30\n",
      "1185/1185 [==============================] - 1s 760us/sample - loss: 0.3030\n",
      "Epoch 18/30\n",
      "1185/1185 [==============================] - 1s 773us/sample - loss: 0.2490\n",
      "Epoch 19/30\n",
      "1185/1185 [==============================] - 1s 769us/sample - loss: 0.2354\n",
      "Epoch 20/30\n",
      "1185/1185 [==============================] - 1s 828us/sample - loss: 0.2554\n",
      "Epoch 21/30\n",
      "1185/1185 [==============================] - 1s 938us/sample - loss: 0.2110\n",
      "Epoch 22/30\n",
      "1185/1185 [==============================] - 1s 853us/sample - loss: 0.2034\n",
      "Epoch 23/30\n",
      "1185/1185 [==============================] - 1s 823us/sample - loss: 0.1969\n",
      "Epoch 24/30\n",
      "1185/1185 [==============================] - 1s 868us/sample - loss: 0.3238\n",
      "Epoch 25/30\n",
      "1185/1185 [==============================] - 1s 948us/sample - loss: 0.2812\n",
      "Epoch 26/30\n",
      "1185/1185 [==============================] - 1s 882us/sample - loss: 0.2260\n",
      "Epoch 27/30\n",
      "1185/1185 [==============================] - 1s 847us/sample - loss: 0.2234\n",
      "Epoch 28/30\n",
      "1185/1185 [==============================] - 1s 833us/sample - loss: 0.1972\n",
      "Epoch 29/30\n",
      "1185/1185 [==============================] - 1s 872us/sample - loss: 0.1866\n",
      "Epoch 30/30\n",
      "1185/1185 [==============================] - 1s 863us/sample - loss: 0.2698\n",
      "Train on 1185 samples\n",
      "Epoch 1/30\n",
      "1185/1185 [==============================] - 2s 1ms/sample - loss: 0.7104\n",
      "Epoch 2/30\n",
      "1185/1185 [==============================] - 1s 910us/sample - loss: 0.5726\n",
      "Epoch 3/30\n",
      "1185/1185 [==============================] - 1s 913us/sample - loss: 0.5480\n",
      "Epoch 4/30\n",
      "1185/1185 [==============================] - 1s 907us/sample - loss: 0.4468\n",
      "Epoch 5/30\n",
      "1185/1185 [==============================] - 1s 866us/sample - loss: 0.4353\n",
      "Epoch 6/30\n",
      "1185/1185 [==============================] - 1s 847us/sample - loss: 0.4514\n",
      "Epoch 7/30\n",
      "1185/1185 [==============================] - 1s 850us/sample - loss: 0.4117\n",
      "Epoch 8/30\n",
      "1185/1185 [==============================] - 1s 860us/sample - loss: 0.4032\n",
      "Epoch 9/30\n",
      "1185/1185 [==============================] - 1s 882us/sample - loss: 0.3627\n",
      "Epoch 10/30\n",
      "1185/1185 [==============================] - 1s 971us/sample - loss: 0.3243\n",
      "Epoch 11/30\n",
      "1185/1185 [==============================] - 1s 880us/sample - loss: 0.3760\n",
      "Epoch 12/30\n",
      "1185/1185 [==============================] - 1s 839us/sample - loss: 0.3362\n",
      "Epoch 13/30\n",
      "1185/1185 [==============================] - 1s 859us/sample - loss: 0.3010\n",
      "Epoch 14/30\n",
      "1185/1185 [==============================] - 1s 839us/sample - loss: 0.2829\n",
      "Epoch 15/30\n",
      "1185/1185 [==============================] - 1s 848us/sample - loss: 0.2491\n",
      "Epoch 16/30\n",
      "1185/1185 [==============================] - 1s 850us/sample - loss: 0.2595\n",
      "Epoch 17/30\n",
      "1185/1185 [==============================] - 1s 841us/sample - loss: 0.2266\n",
      "Epoch 18/30\n",
      "1185/1185 [==============================] - 1s 852us/sample - loss: 0.2748\n",
      "Epoch 19/30\n",
      "1185/1185 [==============================] - 1s 833us/sample - loss: 0.2927\n",
      "Epoch 20/30\n",
      "1185/1185 [==============================] - 1s 890us/sample - loss: 0.2292\n",
      "Epoch 21/30\n",
      "1185/1185 [==============================] - 1s 848us/sample - loss: 0.2318\n",
      "Epoch 22/30\n",
      "1185/1185 [==============================] - 1s 872us/sample - loss: 0.2516\n",
      "Epoch 23/30\n",
      "1185/1185 [==============================] - 1s 869us/sample - loss: 0.2182\n",
      "Epoch 24/30\n",
      "1185/1185 [==============================] - 1s 854us/sample - loss: 0.2527\n",
      "Epoch 25/30\n",
      "1185/1185 [==============================] - 1s 852us/sample - loss: 0.2224\n",
      "Epoch 26/30\n",
      "1185/1185 [==============================] - 1s 862us/sample - loss: 0.1929\n",
      "Epoch 27/30\n",
      "1185/1185 [==============================] - 1s 849us/sample - loss: 0.2007\n",
      "Epoch 28/30\n",
      "1185/1185 [==============================] - 1s 855us/sample - loss: 0.1679\n",
      "Epoch 29/30\n",
      "1185/1185 [==============================] - 1s 875us/sample - loss: 0.1817\n",
      "Epoch 30/30\n",
      "1185/1185 [==============================] - 1s 884us/sample - loss: 0.2066\n",
      "Train on 1185 samples\n",
      "Epoch 1/30\n",
      "1185/1185 [==============================] - 2s 1ms/sample - loss: 0.6998\n",
      "Epoch 2/30\n",
      "1185/1185 [==============================] - 1s 914us/sample - loss: 0.5718\n",
      "Epoch 3/30\n",
      "1185/1185 [==============================] - 1s 866us/sample - loss: 0.5093\n",
      "Epoch 4/30\n",
      "1185/1185 [==============================] - 1s 940us/sample - loss: 0.4973\n",
      "Epoch 5/30\n",
      "1185/1185 [==============================] - 1s 865us/sample - loss: 0.4333\n",
      "Epoch 6/30\n",
      "1185/1185 [==============================] - 1s 890us/sample - loss: 0.4462\n",
      "Epoch 7/30\n",
      "1185/1185 [==============================] - 1s 905us/sample - loss: 0.4126\n",
      "Epoch 8/30\n",
      "1185/1185 [==============================] - 1s 858us/sample - loss: 0.3666\n",
      "Epoch 9/30\n",
      "1185/1185 [==============================] - 1s 866us/sample - loss: 0.3246\n",
      "Epoch 10/30\n",
      "1185/1185 [==============================] - 1s 884us/sample - loss: 0.3424\n",
      "Epoch 11/30\n",
      "1185/1185 [==============================] - 1s 857us/sample - loss: 0.2947\n",
      "Epoch 12/30\n",
      "1185/1185 [==============================] - 1s 874us/sample - loss: 0.3347\n",
      "Epoch 13/30\n",
      "1185/1185 [==============================] - 1s 863us/sample - loss: 0.4966\n",
      "Epoch 14/30\n",
      "1185/1185 [==============================] - 1s 898us/sample - loss: 0.3890\n",
      "Epoch 15/30\n",
      "1185/1185 [==============================] - 1s 899us/sample - loss: 0.2959\n",
      "Epoch 16/30\n",
      "1185/1185 [==============================] - 1s 905us/sample - loss: 0.2897\n",
      "Epoch 17/30\n",
      "1185/1185 [==============================] - 1s 838us/sample - loss: 0.2643\n",
      "Epoch 18/30\n",
      "1185/1185 [==============================] - 1s 861us/sample - loss: 0.2650\n",
      "Epoch 19/30\n",
      "1185/1185 [==============================] - 1s 873us/sample - loss: 0.2329\n",
      "Epoch 20/30\n",
      "1185/1185 [==============================] - 1s 864us/sample - loss: 0.2372\n",
      "Epoch 21/30\n",
      "1185/1185 [==============================] - 1s 851us/sample - loss: 0.2621\n",
      "Epoch 22/30\n",
      "1185/1185 [==============================] - 1s 866us/sample - loss: 0.2589\n",
      "Epoch 23/30\n",
      "1185/1185 [==============================] - 1s 857us/sample - loss: 0.2489\n",
      "Epoch 24/30\n",
      "1185/1185 [==============================] - 1s 858us/sample - loss: 0.2734\n",
      "Epoch 25/30\n",
      "1185/1185 [==============================] - 1s 879us/sample - loss: 0.2017\n",
      "Epoch 26/30\n",
      "1185/1185 [==============================] - 1s 869us/sample - loss: 0.1848\n",
      "Epoch 27/30\n",
      "1185/1185 [==============================] - 1s 857us/sample - loss: 0.2258\n",
      "Epoch 28/30\n",
      "1185/1185 [==============================] - 1s 864us/sample - loss: 0.1828\n",
      "Epoch 29/30\n",
      "1185/1185 [==============================] - 1s 849us/sample - loss: 0.1823\n",
      "Epoch 30/30\n",
      "1185/1185 [==============================] - 1s 844us/sample - loss: 0.1770\n"
     ]
    }
   ],
   "source": [
    "final_models = []\n",
    "\n",
    "features_to_try = [corr_features_3, corr_features_4, uni_features_2, uni_features_3]\n",
    "\n",
    "scores, models, predictions = [],[],[]\n",
    "\n",
    "for features in features_to_try:\n",
    "    \n",
    "    # Choosing only the relevant features\n",
    "    X_relevant = X_normalized[features]\n",
    "\n",
    "    # creating NN\n",
    "    model = create_network(number_of_features = X_relevant.shape[1])\n",
    "\n",
    "    # Fitting NN\n",
    "    model.fit(X_relevant.values, y_normalized, epochs = 30)\n",
    "\n",
    "    final_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.read_csv('X_test.csv', float_precision='high')\n",
    "\n",
    "# replacing the nan values\n",
    "X_final = X_final.fillna(X.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = X_final.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116890.145646</td>\n",
       "      <td>4682.826460</td>\n",
       "      <td>102084.432558</td>\n",
       "      <td>988.163180</td>\n",
       "      <td>10412.331659</td>\n",
       "      <td>10.481227</td>\n",
       "      <td>103604.878991</td>\n",
       "      <td>1.095767e+06</td>\n",
       "      <td>100602.794631</td>\n",
       "      <td>...</td>\n",
       "      <td>11.027043</td>\n",
       "      <td>11.009213</td>\n",
       "      <td>1030.608247</td>\n",
       "      <td>1018.364228</td>\n",
       "      <td>108762.467652</td>\n",
       "      <td>105073.764746</td>\n",
       "      <td>7347.221554</td>\n",
       "      <td>8.598623</td>\n",
       "      <td>102506.589322</td>\n",
       "      <td>2.350805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104149.957877</td>\n",
       "      <td>3161.012055</td>\n",
       "      <td>93566.104799</td>\n",
       "      <td>1037.879907</td>\n",
       "      <td>11232.156777</td>\n",
       "      <td>10.143346</td>\n",
       "      <td>104871.393293</td>\n",
       "      <td>1.083111e+06</td>\n",
       "      <td>102331.038815</td>\n",
       "      <td>...</td>\n",
       "      <td>10.541972</td>\n",
       "      <td>10.391822</td>\n",
       "      <td>1049.620654</td>\n",
       "      <td>972.516069</td>\n",
       "      <td>108773.164038</td>\n",
       "      <td>105822.141259</td>\n",
       "      <td>5687.349133</td>\n",
       "      <td>9.791258</td>\n",
       "      <td>107449.718830</td>\n",
       "      <td>2.278208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91332.402246</td>\n",
       "      <td>3922.735224</td>\n",
       "      <td>108810.999713</td>\n",
       "      <td>1008.536233</td>\n",
       "      <td>12030.362103</td>\n",
       "      <td>10.811671</td>\n",
       "      <td>107372.736023</td>\n",
       "      <td>1.075590e+06</td>\n",
       "      <td>104247.270565</td>\n",
       "      <td>...</td>\n",
       "      <td>10.648721</td>\n",
       "      <td>10.979466</td>\n",
       "      <td>973.772111</td>\n",
       "      <td>1068.819601</td>\n",
       "      <td>106851.090304</td>\n",
       "      <td>104651.998344</td>\n",
       "      <td>6510.915424</td>\n",
       "      <td>10.993281</td>\n",
       "      <td>107366.747806</td>\n",
       "      <td>2.171415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93281.714961</td>\n",
       "      <td>3707.283134</td>\n",
       "      <td>86947.473251</td>\n",
       "      <td>947.048927</td>\n",
       "      <td>10037.466655</td>\n",
       "      <td>10.208015</td>\n",
       "      <td>104871.393293</td>\n",
       "      <td>1.042872e+06</td>\n",
       "      <td>103283.424614</td>\n",
       "      <td>...</td>\n",
       "      <td>10.255209</td>\n",
       "      <td>10.566875</td>\n",
       "      <td>918.617516</td>\n",
       "      <td>1003.124009</td>\n",
       "      <td>104245.538474</td>\n",
       "      <td>102301.224747</td>\n",
       "      <td>6832.795027</td>\n",
       "      <td>9.845355</td>\n",
       "      <td>100865.094552</td>\n",
       "      <td>2.222927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88434.057156</td>\n",
       "      <td>5184.106152</td>\n",
       "      <td>85396.992336</td>\n",
       "      <td>1101.076469</td>\n",
       "      <td>10083.474388</td>\n",
       "      <td>10.124108</td>\n",
       "      <td>109507.125721</td>\n",
       "      <td>1.013667e+06</td>\n",
       "      <td>102676.240326</td>\n",
       "      <td>...</td>\n",
       "      <td>10.482693</td>\n",
       "      <td>10.784100</td>\n",
       "      <td>945.230640</td>\n",
       "      <td>1032.396697</td>\n",
       "      <td>106180.279333</td>\n",
       "      <td>104253.493703</td>\n",
       "      <td>6586.500123</td>\n",
       "      <td>11.953965</td>\n",
       "      <td>101665.694524</td>\n",
       "      <td>2.057716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id             x0           x1             x2           x3            x4  \\\n",
       "0  0.0  116890.145646  4682.826460  102084.432558   988.163180  10412.331659   \n",
       "1  1.0  104149.957877  3161.012055   93566.104799  1037.879907  11232.156777   \n",
       "2  2.0   91332.402246  3922.735224  108810.999713  1008.536233  12030.362103   \n",
       "3  3.0   93281.714961  3707.283134   86947.473251   947.048927  10037.466655   \n",
       "4  4.0   88434.057156  5184.106152   85396.992336  1101.076469  10083.474388   \n",
       "\n",
       "          x5             x6            x7             x8  ...       x822  \\\n",
       "0  10.481227  103604.878991  1.095767e+06  100602.794631  ...  11.027043   \n",
       "1  10.143346  104871.393293  1.083111e+06  102331.038815  ...  10.541972   \n",
       "2  10.811671  107372.736023  1.075590e+06  104247.270565  ...  10.648721   \n",
       "3  10.208015  104871.393293  1.042872e+06  103283.424614  ...  10.255209   \n",
       "4  10.124108  109507.125721  1.013667e+06  102676.240326  ...  10.482693   \n",
       "\n",
       "        x823         x824         x825           x826           x827  \\\n",
       "0  11.009213  1030.608247  1018.364228  108762.467652  105073.764746   \n",
       "1  10.391822  1049.620654   972.516069  108773.164038  105822.141259   \n",
       "2  10.979466   973.772111  1068.819601  106851.090304  104651.998344   \n",
       "3  10.566875   918.617516  1003.124009  104245.538474  102301.224747   \n",
       "4  10.784100   945.230640  1032.396697  106180.279333  104253.493703   \n",
       "\n",
       "          x828       x829           x830      x831  \n",
       "0  7347.221554   8.598623  102506.589322  2.350805  \n",
       "1  5687.349133   9.791258  107449.718830  2.278208  \n",
       "2  6510.915424  10.993281  107366.747806  2.171415  \n",
       "3  6832.795027   9.845355  100865.094552  2.222927  \n",
       "4  6586.500123  11.953965  101665.694524  2.057716  \n",
       "\n",
       "[5 rows x 833 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = X_final.fillna(X_final.median()).drop('id', axis=1)\n",
    "\n",
    "# Normalizing the X values\n",
    "X_final_normalized = (X_final - X_final.mean()) / X_final.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "# making predictions based on the features that got the best scores\n",
    "X_final_normalized_1 = X_final_normalized[features_to_try[0]]\n",
    "X_final_normalized_2 = X_final_normalized[features_to_try[1]]\n",
    "X_final_normalized_3 = X_final_normalized[features_to_try[2]]\n",
    "X_final_normalized_4 = X_final_normalized[features_to_try[3]]\n",
    "\n",
    "y_final_pred_1 = final_models[0].predict(X_final_normalized_1)\n",
    "y_final_pred_1 = y_final_pred_1 * y_std + y_mean\n",
    "y_final_pred_1 = y_final_pred_1.reshape(len(y_final_pred_1))\n",
    "\n",
    "y_final_pred_2 = final_models[1].predict(X_final_normalized_2)\n",
    "y_final_pred_2 = y_final_pred_2 * y_std + y_mean\n",
    "y_final_pred_2 = y_final_pred_2.reshape(len(y_final_pred_2))\n",
    "\n",
    "y_final_pred_3 = final_models[2].predict(X_final_normalized_3)\n",
    "y_final_pred_3 = y_final_pred_3 * y_std + y_mean\n",
    "y_final_pred_3 = y_final_pred_3.reshape(len(y_final_pred_3))\n",
    "\n",
    "y_final_pred_4 = final_models[3].predict(X_final_normalized_4)\n",
    "y_final_pred_4 = y_final_pred_4 * y_std + y_mean\n",
    "y_final_pred_4 = y_final_pred_4.reshape(len(y_final_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the mean of the predictions\n",
    "y_final_pred = (y_final_pred_1 + y_final_pred_2 + y_final_pred_3 + y_final_pred_4) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_pred = pd.concat([ids,pd.Series(y_final_pred)], keys = ['id','y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.965652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.992371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.428436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.635567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.814377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id          y\n",
       "0  0.0  72.965652\n",
       "1  1.0  74.992371\n",
       "2  2.0  88.428436\n",
       "3  3.0  73.635567\n",
       "4  4.0  79.814377"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_pred.to_csv('y_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
