{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train/Test splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Class Imbalance\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import (BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, VotingClassifier, \n",
    "GradientBoostingClassifier, AdaBoostClassifier)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "\n",
    "# Neural networks\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "# Error\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "X = pd.read_csv('X_train.csv', float_precision='high').drop('id', axis=1)\n",
    "X_final = pd.read_csv('X_test.csv', float_precision='high').drop('id', axis=1)\n",
    "y = pd.read_csv('y_train.csv', float_precision='high').drop('id', axis=1)\n",
    "\n",
    "# replacing the missing values with the median of that column\n",
    "#X = X.fillna(X.median())\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x990</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.099144</td>\n",
       "      <td>0.918165</td>\n",
       "      <td>-1.227394</td>\n",
       "      <td>0.887061</td>\n",
       "      <td>1.182734</td>\n",
       "      <td>-0.371802</td>\n",
       "      <td>-0.127331</td>\n",
       "      <td>1.201702</td>\n",
       "      <td>1.825839</td>\n",
       "      <td>2.944655</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111422</td>\n",
       "      <td>1.566261</td>\n",
       "      <td>-1.656656</td>\n",
       "      <td>-0.412988</td>\n",
       "      <td>2.803183</td>\n",
       "      <td>-3.253815</td>\n",
       "      <td>-2.042599</td>\n",
       "      <td>3.497246</td>\n",
       "      <td>-1.275422</td>\n",
       "      <td>2.440708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366477</td>\n",
       "      <td>0.933802</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.430073</td>\n",
       "      <td>1.029673</td>\n",
       "      <td>-0.613771</td>\n",
       "      <td>0.364698</td>\n",
       "      <td>1.140867</td>\n",
       "      <td>0.182811</td>\n",
       "      <td>-0.344876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672386</td>\n",
       "      <td>-0.003721</td>\n",
       "      <td>-0.496326</td>\n",
       "      <td>0.672818</td>\n",
       "      <td>-0.546066</td>\n",
       "      <td>-0.227112</td>\n",
       "      <td>0.291441</td>\n",
       "      <td>-0.150495</td>\n",
       "      <td>0.156421</td>\n",
       "      <td>0.714252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.425879</td>\n",
       "      <td>-0.802152</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.820036</td>\n",
       "      <td>1.490237</td>\n",
       "      <td>-0.888121</td>\n",
       "      <td>0.769524</td>\n",
       "      <td>1.059020</td>\n",
       "      <td>0.854806</td>\n",
       "      <td>-0.077359</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.031358</td>\n",
       "      <td>-0.085724</td>\n",
       "      <td>-0.557461</td>\n",
       "      <td>-0.091904</td>\n",
       "      <td>-0.123858</td>\n",
       "      <td>0.387162</td>\n",
       "      <td>1.031941</td>\n",
       "      <td>0.766522</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>-0.046364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822922</td>\n",
       "      <td>-0.843041</td>\n",
       "      <td>-0.734624</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.123783</td>\n",
       "      <td>-1.777226</td>\n",
       "      <td>0.364601</td>\n",
       "      <td>0.425521</td>\n",
       "      <td>1.265122</td>\n",
       "      <td>0.734897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118974</td>\n",
       "      <td>1.271367</td>\n",
       "      <td>-1.518161</td>\n",
       "      <td>-0.315441</td>\n",
       "      <td>0.218074</td>\n",
       "      <td>-1.880067</td>\n",
       "      <td>-0.495170</td>\n",
       "      <td>1.418946</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>1.475484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.285342</td>\n",
       "      <td>-0.641116</td>\n",
       "      <td>0.436524</td>\n",
       "      <td>-0.618663</td>\n",
       "      <td>0.319982</td>\n",
       "      <td>-1.160489</td>\n",
       "      <td>0.528379</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>-0.156210</td>\n",
       "      <td>-0.756133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.997750</td>\n",
       "      <td>-1.008573</td>\n",
       "      <td>-0.404263</td>\n",
       "      <td>0.304188</td>\n",
       "      <td>0.313034</td>\n",
       "      <td>-0.514287</td>\n",
       "      <td>0.701526</td>\n",
       "      <td>0.473238</td>\n",
       "      <td>-0.046099</td>\n",
       "      <td>0.492881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.342445</td>\n",
       "      <td>0.199332</td>\n",
       "      <td>-0.090380</td>\n",
       "      <td>0.458183</td>\n",
       "      <td>0.891484</td>\n",
       "      <td>-0.447942</td>\n",
       "      <td>0.327099</td>\n",
       "      <td>-0.129950</td>\n",
       "      <td>0.453594</td>\n",
       "      <td>0.089181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.786505</td>\n",
       "      <td>0.208726</td>\n",
       "      <td>-1.030579</td>\n",
       "      <td>-0.362479</td>\n",
       "      <td>0.749629</td>\n",
       "      <td>-1.429047</td>\n",
       "      <td>-0.155704</td>\n",
       "      <td>0.745928</td>\n",
       "      <td>-0.696751</td>\n",
       "      <td>1.228423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.043826</td>\n",
       "      <td>-0.181633</td>\n",
       "      <td>-0.322609</td>\n",
       "      <td>0.346912</td>\n",
       "      <td>0.077354</td>\n",
       "      <td>-1.104049</td>\n",
       "      <td>0.541301</td>\n",
       "      <td>0.254954</td>\n",
       "      <td>-0.099049</td>\n",
       "      <td>-0.396617</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.064404</td>\n",
       "      <td>-0.096151</td>\n",
       "      <td>-0.445242</td>\n",
       "      <td>-0.284852</td>\n",
       "      <td>0.563819</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>0.389729</td>\n",
       "      <td>0.424350</td>\n",
       "      <td>-0.608710</td>\n",
       "      <td>0.461548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.681491</td>\n",
       "      <td>-0.673945</td>\n",
       "      <td>-0.588701</td>\n",
       "      <td>0.429639</td>\n",
       "      <td>-0.098095</td>\n",
       "      <td>-1.521309</td>\n",
       "      <td>0.258657</td>\n",
       "      <td>0.127858</td>\n",
       "      <td>1.301962</td>\n",
       "      <td>-0.106590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382918</td>\n",
       "      <td>0.850127</td>\n",
       "      <td>-0.611081</td>\n",
       "      <td>-1.367277</td>\n",
       "      <td>0.323803</td>\n",
       "      <td>-1.988082</td>\n",
       "      <td>-0.513081</td>\n",
       "      <td>1.560772</td>\n",
       "      <td>-0.284178</td>\n",
       "      <td>1.056016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.030290</td>\n",
       "      <td>0.810890</td>\n",
       "      <td>0.199345</td>\n",
       "      <td>0.200558</td>\n",
       "      <td>0.509789</td>\n",
       "      <td>-0.670375</td>\n",
       "      <td>-1.552185</td>\n",
       "      <td>0.669737</td>\n",
       "      <td>1.494708</td>\n",
       "      <td>1.821085</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.753024</td>\n",
       "      <td>0.722741</td>\n",
       "      <td>-1.031887</td>\n",
       "      <td>-1.995433</td>\n",
       "      <td>1.653382</td>\n",
       "      <td>-3.262406</td>\n",
       "      <td>-0.529423</td>\n",
       "      <td>2.028094</td>\n",
       "      <td>0.150517</td>\n",
       "      <td>-1.492435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.201803</td>\n",
       "      <td>-0.342499</td>\n",
       "      <td>0.699407</td>\n",
       "      <td>0.679692</td>\n",
       "      <td>0.908805</td>\n",
       "      <td>-0.647258</td>\n",
       "      <td>0.804946</td>\n",
       "      <td>0.653396</td>\n",
       "      <td>1.149530</td>\n",
       "      <td>-1.027472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.962504</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>-0.836563</td>\n",
       "      <td>-0.539060</td>\n",
       "      <td>0.745173</td>\n",
       "      <td>-1.490457</td>\n",
       "      <td>0.596143</td>\n",
       "      <td>1.488954</td>\n",
       "      <td>0.198124</td>\n",
       "      <td>0.968845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0 -1.099144  0.918165 -1.227394  0.887061  1.182734 -0.371802 -0.127331   \n",
       "1  0.366477  0.933802  0.061234  0.430073  1.029673 -0.613771  0.364698   \n",
       "2 -0.425879 -0.802152  0.002718  0.820036  1.490237 -0.888121  0.769524   \n",
       "3  0.822922 -0.843041 -0.734624 -0.000040  0.123783 -1.777226  0.364601   \n",
       "4 -0.285342 -0.641116  0.436524 -0.618663  0.319982 -1.160489  0.528379   \n",
       "5 -0.342445  0.199332 -0.090380  0.458183  0.891484 -0.447942  0.327099   \n",
       "6 -0.043826 -0.181633 -0.322609  0.346912  0.077354 -1.104049  0.541301   \n",
       "7 -0.681491 -0.673945 -0.588701  0.429639 -0.098095 -1.521309  0.258657   \n",
       "8 -0.030290  0.810890  0.199345  0.200558  0.509789 -0.670375 -1.552185   \n",
       "9  0.201803 -0.342499  0.699407  0.679692  0.908805 -0.647258  0.804946   \n",
       "\n",
       "         x7        x8        x9  ...      x990      x991      x992      x993  \\\n",
       "0  1.201702  1.825839  2.944655  ... -1.111422  1.566261 -1.656656 -0.412988   \n",
       "1  1.140867  0.182811 -0.344876  ... -0.672386 -0.003721 -0.496326  0.672818   \n",
       "2  1.059020  0.854806 -0.077359  ... -1.031358 -0.085724 -0.557461 -0.091904   \n",
       "3  0.425521  1.265122  0.734897  ... -0.118974  1.271367 -1.518161 -0.315441   \n",
       "4  0.337300 -0.156210 -0.756133  ... -0.997750 -1.008573 -0.404263  0.304188   \n",
       "5 -0.129950  0.453594  0.089181  ... -0.786505  0.208726 -1.030579 -0.362479   \n",
       "6  0.254954 -0.099049 -0.396617  ... -1.064404 -0.096151 -0.445242 -0.284852   \n",
       "7  0.127858  1.301962 -0.106590  ... -0.382918  0.850127 -0.611081 -1.367277   \n",
       "8  0.669737  1.494708  1.821085  ... -2.753024  0.722741 -1.031887 -1.995433   \n",
       "9  0.653396  1.149530 -1.027472  ... -0.962504  0.131858 -0.836563 -0.539060   \n",
       "\n",
       "       x994      x995      x996      x997      x998      x999  \n",
       "0  2.803183 -3.253815 -2.042599  3.497246 -1.275422  2.440708  \n",
       "1 -0.546066 -0.227112  0.291441 -0.150495  0.156421  0.714252  \n",
       "2 -0.123858  0.387162  1.031941  0.766522  0.339105 -0.046364  \n",
       "3  0.218074 -1.880067 -0.495170  1.418946 -0.201938  1.475484  \n",
       "4  0.313034 -0.514287  0.701526  0.473238 -0.046099  0.492881  \n",
       "5  0.749629 -1.429047 -0.155704  0.745928 -0.696751  1.228423  \n",
       "6  0.563819  0.120010  0.389729  0.424350 -0.608710  0.461548  \n",
       "7  0.323803 -1.988082 -0.513081  1.560772 -0.284178  1.056016  \n",
       "8  1.653382 -3.262406 -0.529423  2.028094  0.150517 -1.492435  \n",
       "9  0.745173 -1.490457  0.596143  1.488954  0.198124  0.968845  \n",
       "\n",
       "[10 rows x 1000 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "#sss.get_n_splits(X, y)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3600\n",
       "2     600\n",
       "0     600\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of each class in the training set\n",
    "y.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "#X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "X = pd.concat([X, y], axis=1)\n",
    "# separate minority and majority classes\n",
    "class_0 = X[X.y==0]\n",
    "class_1 = X[X.y==1]\n",
    "class_2 = X[X.y==2]\n",
    "\n",
    "# upsample minority\n",
    "class_0 = resample(class_0, \n",
    "                   replace=True, # sample with replacement\n",
    "                   n_samples=len(class_1), # match number in majority class\n",
    "                   random_state=27) # reproducible results\n",
    "# upsample minority\n",
    "class_2 = resample(class_2, \n",
    "                   replace=True, # sample with replacement\n",
    "                   n_samples=len(class_1), # match number in majority class\n",
    "                   random_state=27) # reproducible results\n",
    "\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([class_0, class_1, class_2])\n",
    "\n",
    "y_upsampled = upsampled.y\n",
    "X_upsampled = upsampled.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_upsampled' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-61ec9e9bee6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check new class counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_upsampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train_upsampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_upsampled' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# check new class counts\n",
    "print(y_train_upsampled.value_counts())\n",
    "X_train_upsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy={0: X.shape[0], 1: X.shape[0], 2: X.shape[0]}, random_state=27)\n",
    "X, y = sm.fit_sample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x990</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.096023</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>-0.060079</td>\n",
       "      <td>0.291787</td>\n",
       "      <td>0.959385</td>\n",
       "      <td>-0.692944</td>\n",
       "      <td>-0.311773</td>\n",
       "      <td>0.704975</td>\n",
       "      <td>-0.271186</td>\n",
       "      <td>-0.563955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232652</td>\n",
       "      <td>-0.043905</td>\n",
       "      <td>-0.736941</td>\n",
       "      <td>0.994046</td>\n",
       "      <td>0.429387</td>\n",
       "      <td>0.199501</td>\n",
       "      <td>0.476326</td>\n",
       "      <td>0.747109</td>\n",
       "      <td>0.103769</td>\n",
       "      <td>-0.632316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>-1.048684</td>\n",
       "      <td>0.273354</td>\n",
       "      <td>-0.654514</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>0.849184</td>\n",
       "      <td>-0.067237</td>\n",
       "      <td>-0.488956</td>\n",
       "      <td>1.691567</td>\n",
       "      <td>-0.409806</td>\n",
       "      <td>-1.329159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358177</td>\n",
       "      <td>0.472728</td>\n",
       "      <td>-0.250097</td>\n",
       "      <td>0.711923</td>\n",
       "      <td>1.117118</td>\n",
       "      <td>-0.345489</td>\n",
       "      <td>0.640481</td>\n",
       "      <td>0.880876</td>\n",
       "      <td>-0.711542</td>\n",
       "      <td>0.078018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>0.415622</td>\n",
       "      <td>-0.125793</td>\n",
       "      <td>-0.090027</td>\n",
       "      <td>-0.277413</td>\n",
       "      <td>-0.303201</td>\n",
       "      <td>-0.224223</td>\n",
       "      <td>-0.745746</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.779969</td>\n",
       "      <td>-0.656770</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.236626</td>\n",
       "      <td>0.806601</td>\n",
       "      <td>0.735825</td>\n",
       "      <td>1.304960</td>\n",
       "      <td>0.327683</td>\n",
       "      <td>-0.326636</td>\n",
       "      <td>1.535137</td>\n",
       "      <td>0.719197</td>\n",
       "      <td>0.291618</td>\n",
       "      <td>-0.367624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.056069</td>\n",
       "      <td>-0.169683</td>\n",
       "      <td>-0.376146</td>\n",
       "      <td>0.557980</td>\n",
       "      <td>0.467540</td>\n",
       "      <td>-1.386400</td>\n",
       "      <td>0.615987</td>\n",
       "      <td>0.794732</td>\n",
       "      <td>-0.043987</td>\n",
       "      <td>-1.261437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647287</td>\n",
       "      <td>-0.239682</td>\n",
       "      <td>-0.428079</td>\n",
       "      <td>-0.616974</td>\n",
       "      <td>0.656375</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>0.572355</td>\n",
       "      <td>0.905697</td>\n",
       "      <td>0.303488</td>\n",
       "      <td>-0.095536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>0.486108</td>\n",
       "      <td>-0.418240</td>\n",
       "      <td>0.875455</td>\n",
       "      <td>-0.467575</td>\n",
       "      <td>0.717754</td>\n",
       "      <td>-0.408097</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>1.011524</td>\n",
       "      <td>-0.020505</td>\n",
       "      <td>-0.143252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.892487</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.371115</td>\n",
       "      <td>0.085639</td>\n",
       "      <td>0.976408</td>\n",
       "      <td>0.175409</td>\n",
       "      <td>0.238641</td>\n",
       "      <td>0.080604</td>\n",
       "      <td>-0.110289</td>\n",
       "      <td>-0.485794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        x2        x3        x4        x5        x6  \\\n",
       "148  -0.096023  0.130199 -0.060079  0.291787  0.959385 -0.692944 -0.311773   \n",
       "4347 -1.048684  0.273354 -0.654514  0.323813  0.849184 -0.067237 -0.488956   \n",
       "2342  0.415622 -0.125793 -0.090027 -0.277413 -0.303201 -0.224223 -0.745746   \n",
       "178   0.056069 -0.169683 -0.376146  0.557980  0.467540 -1.386400  0.615987   \n",
       "4317  0.486108 -0.418240  0.875455 -0.467575  0.717754 -0.408097  0.000380   \n",
       "\n",
       "            x7        x8        x9  ...      x990      x991      x992  \\\n",
       "148   0.704975 -0.271186 -0.563955  ... -0.232652 -0.043905 -0.736941   \n",
       "4347  1.691567 -0.409806 -1.329159  ... -0.358177  0.472728 -0.250097   \n",
       "2342  0.362637  0.779969 -0.656770  ... -1.236626  0.806601  0.735825   \n",
       "178   0.794732 -0.043987 -1.261437  ... -0.647287 -0.239682 -0.428079   \n",
       "4317  1.011524 -0.020505 -0.143252  ... -0.892487  0.029166  0.371115   \n",
       "\n",
       "          x993      x994      x995      x996      x997      x998      x999  \n",
       "148   0.994046  0.429387  0.199501  0.476326  0.747109  0.103769 -0.632316  \n",
       "4347  0.711923  1.117118 -0.345489  0.640481  0.880876 -0.711542  0.078018  \n",
       "2342  1.304960  0.327683 -0.326636  1.535137  0.719197  0.291618 -0.367624  \n",
       "178  -0.616974  0.656375  0.539020  0.572355  0.905697  0.303488 -0.095536  \n",
       "4317  0.085639  0.976408  0.175409  0.238641  0.080604 -0.110289 -0.485794  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Classifiers -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear').fit(X_train_upsampled, y_train_upsampled)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = RidgeClassifier(solver='liblinear').fit(X_train_upsampled, y_train_upsampled)\n",
    "y_pred = rg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used on the dataset without upsampling first \n",
    "bbc = BalancedBaggingClassifier(random_state=42).fit(X_train, y_train)\n",
    "y_pred = bbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1075\n",
    "np.random.seed(seed)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "rg = RidgeClassifier()\n",
    "\n",
    "clf_array = [rf, knn, et, svc, rg]\n",
    "bagging_pred = []\n",
    "for clf in clf_array:\n",
    "    #vanilla_scores = cross_val_score(clf, X_train_upsampled, y_train_upsampled, cv=10, n_jobs=-1)\n",
    "    bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=3, random_state=seed)\n",
    "    bagging_scores = cross_val_score(bagging_clf, X_train_upsampled, y_train_upsampled, cv=10, n_jobs=-1)\n",
    "    \n",
    "\n",
    "    print(\"Mean:\",vanilla_scores.mean() ,\"std:\", vanilla_scores.std(), \"Type: \", clf.__class__.__name__)\n",
    "    print(\"Mean:\",bagging_scores.mean() ,\"std:\", bagging_scores.std(), \"Type: Bagging\", clf.__class__.__name__)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = BaggingClassifier(RandomForestClassifier())\n",
    "et = BaggingClassifier(ExtraTreesClassifier())\n",
    "knn = BaggingClassifier(KNeighborsClassifier())\n",
    "svc = BaggingClassifier(SVC())\n",
    "rg = BaggingClassifier(RidgeClassifier())\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('Random Forests', rf), ('Extra Trees', et), ('KNeighbors', knn), ('SVC', svc), ('Ridge Classifier', rg)], voting='hard').fit(X_train_upsampled, y_train_upsampled)\n",
    "y_pred = eclf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting + Bagging + Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = BaggingClassifier(RandomForestClassifier())\n",
    "#et = BaggingClassifier(ExtraTreesClassifier())\n",
    "knn = BaggingClassifier(KNeighborsClassifier())\n",
    "svc = BaggingClassifier(SVC())\n",
    "rg = BaggingClassifier(RidgeClassifier())\n",
    "#ada_boost = AdaBoostClassifier()\n",
    "#grad_boost = GradientBoostingClassifier()\n",
    "xgb_boost = XGBClassifier()\n",
    "boost_array = [ada_boost, grad_boost, xgb_boost]\n",
    "\n",
    "evclf = EnsembleVoteClassifier(clfs=[xgb_boost, rf, knn, svc, rg], voting='hard').fit(X, y)\n",
    "#y_pred_ = evclf.predict(X_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMAC = balanced_accuracy_score(y_test, y_pred_)\n",
    "\n",
    "print(BMAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation score is :  0.9096296296296296\n",
      "[0.9062963  0.90814815 0.91259259 0.91148148]\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation of the results\n",
    "cv_score = cross_val_score(evclf, X, y, cv=4, scoring=('balanced_accuracy'))\n",
    "print('The mean cross-validation score is : ',cv_score.mean())\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the X values\n",
    "X_train_normalized = (X_train_upsampled - X_train_upsampled.mean()) / X_train_upsampled.std()\n",
    "X_test_normalized = (X_test - X_test.mean()) / X_test.std()\n",
    "\n",
    "# Normalizing y values\n",
    "#y_train_mean, y_train_std = y_train_upsampled.to_frame().mean(axis=1), y_train_upsampled.to_frame().std(axis=1)\n",
    "#y_train_normalized = ((y_train_upsampled - y_train_mean) / y_train_std).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the average per-column recall metric\n",
    "    for a multi-class classification problem\n",
    "    \"\"\" \n",
    "    true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=0)  \n",
    "    possible_positives = backend.sum(backend.round(backend.clip(y_true, 0, 1)), axis=0)   \n",
    "    recall = true_positives / (possible_positives + backend.epsilon())    \n",
    "    balanced_recall = backend.mean(recall)\n",
    "    return balanced_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(number_of_features):\n",
    "    model = Sequential([Dense(number_of_features, activation='relu'),\n",
    "                        Dense(1024, activation='relu'),\n",
    "                        Dense(512, activation='relu'),\n",
    "                        Dropout(0.1),\n",
    "                        Dense(1024, activation='relu'),\n",
    "                        Dense(1024, activation='relu'),\n",
    "                        Dropout(0.1),\n",
    "                        Dense(1024, activation='relu'),\n",
    "                        Dropout(0.1),\n",
    "                        Dense(512, activation='relu'),\n",
    "                        Dense(256, activation='relu'),\n",
    "                        Flatten(),\n",
    "                        Dense(128,activation = 'sigmoid'),                         \n",
    "                        Dense(3,activation = 'softmax')])\n",
    "\n",
    "    model.compile(optimizer = 'adam',loss='sparse_categorical_crossentropy',metrics = [balanced_accuracy_score])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing only the relevant features\n",
    "#X_train_relevant = X_train_normalized[features]\n",
    "#X_test_relevant = X_test_normalized[features]\n",
    "\n",
    "# creating NN\n",
    "model = create_network(number_of_features = X.shape[1])\n",
    "\n",
    "# Fitting NN\n",
    "model.fit(X.values, y.values, epochs = 10)\n",
    "\n",
    "# Predicting classes\n",
    "y_pred = model.predict(X_final).argmax(axis=1)\n",
    "#y_pred = y_pred * y_train_std + y_train_mean\n",
    "\n",
    "# Saving the score\n",
    "#score = balanced_accuracy_score(y_test, y_pred.argmax(axis=1))\n",
    "#scores.append(score)\n",
    "\n",
    "# saving the model\n",
    "#models.append(model)\n",
    "\n",
    "# saving the predictions\n",
    "#predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x990</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.393081</td>\n",
       "      <td>-1.266585</td>\n",
       "      <td>-0.534465</td>\n",
       "      <td>-0.017727</td>\n",
       "      <td>0.870355</td>\n",
       "      <td>-1.243459</td>\n",
       "      <td>-0.194805</td>\n",
       "      <td>3.369338</td>\n",
       "      <td>0.518030</td>\n",
       "      <td>1.014564</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.642932</td>\n",
       "      <td>0.524188</td>\n",
       "      <td>-1.297014</td>\n",
       "      <td>-0.299613</td>\n",
       "      <td>2.391213</td>\n",
       "      <td>-1.134149</td>\n",
       "      <td>-1.061005</td>\n",
       "      <td>3.208220</td>\n",
       "      <td>-0.057589</td>\n",
       "      <td>0.591722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973050</td>\n",
       "      <td>0.121111</td>\n",
       "      <td>-0.051525</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.020402</td>\n",
       "      <td>-0.203451</td>\n",
       "      <td>-0.851999</td>\n",
       "      <td>0.623676</td>\n",
       "      <td>-0.142667</td>\n",
       "      <td>-1.082818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802205</td>\n",
       "      <td>-0.881559</td>\n",
       "      <td>0.044385</td>\n",
       "      <td>0.104938</td>\n",
       "      <td>1.400879</td>\n",
       "      <td>0.440617</td>\n",
       "      <td>0.250877</td>\n",
       "      <td>0.920801</td>\n",
       "      <td>0.138718</td>\n",
       "      <td>-0.052341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038292</td>\n",
       "      <td>-0.995839</td>\n",
       "      <td>0.087764</td>\n",
       "      <td>1.868466</td>\n",
       "      <td>-0.438614</td>\n",
       "      <td>-0.226892</td>\n",
       "      <td>0.396370</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.591847</td>\n",
       "      <td>0.904976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509470</td>\n",
       "      <td>1.053428</td>\n",
       "      <td>-1.082730</td>\n",
       "      <td>-0.822194</td>\n",
       "      <td>1.164689</td>\n",
       "      <td>-2.721737</td>\n",
       "      <td>-1.270373</td>\n",
       "      <td>2.793598</td>\n",
       "      <td>0.333958</td>\n",
       "      <td>0.790519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.650431</td>\n",
       "      <td>0.324940</td>\n",
       "      <td>0.404872</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>-0.533394</td>\n",
       "      <td>0.237058</td>\n",
       "      <td>1.755244</td>\n",
       "      <td>-0.291717</td>\n",
       "      <td>-1.512967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343155</td>\n",
       "      <td>-0.255553</td>\n",
       "      <td>0.723408</td>\n",
       "      <td>0.689066</td>\n",
       "      <td>0.756997</td>\n",
       "      <td>0.983355</td>\n",
       "      <td>0.660556</td>\n",
       "      <td>-0.030405</td>\n",
       "      <td>0.180313</td>\n",
       "      <td>-0.427872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345413</td>\n",
       "      <td>0.176561</td>\n",
       "      <td>-0.427172</td>\n",
       "      <td>-0.057769</td>\n",
       "      <td>0.865265</td>\n",
       "      <td>-1.274553</td>\n",
       "      <td>-1.041643</td>\n",
       "      <td>0.644448</td>\n",
       "      <td>1.667168</td>\n",
       "      <td>0.932939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.688064</td>\n",
       "      <td>1.845356</td>\n",
       "      <td>-1.246581</td>\n",
       "      <td>-0.986015</td>\n",
       "      <td>1.381274</td>\n",
       "      <td>-1.549053</td>\n",
       "      <td>-2.936785</td>\n",
       "      <td>2.497881</td>\n",
       "      <td>0.276085</td>\n",
       "      <td>0.167375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.393081 -1.266585 -0.534465 -0.017727  0.870355 -1.243459 -0.194805   \n",
       "1  0.973050  0.121111 -0.051525  0.002681  0.020402 -0.203451 -0.851999   \n",
       "2  0.038292 -0.995839  0.087764  1.868466 -0.438614 -0.226892  0.396370   \n",
       "3  0.650431  0.324940  0.404872  0.028380  0.848341 -0.533394  0.237058   \n",
       "4  0.345413  0.176561 -0.427172 -0.057769  0.865265 -1.274553 -1.041643   \n",
       "\n",
       "         x7        x8        x9  ...      x990      x991      x992      x993  \\\n",
       "0  3.369338  0.518030  1.014564  ... -1.642932  0.524188 -1.297014 -0.299613   \n",
       "1  0.623676 -0.142667 -1.082818  ... -0.802205 -0.881559  0.044385  0.104938   \n",
       "2  0.848138  0.591847  0.904976  ... -0.509470  1.053428 -1.082730 -0.822194   \n",
       "3  1.755244 -0.291717 -1.512967  ... -0.343155 -0.255553  0.723408  0.689066   \n",
       "4  0.644448  1.667168  0.932939  ... -0.688064  1.845356 -1.246581 -0.986015   \n",
       "\n",
       "       x994      x995      x996      x997      x998      x999  \n",
       "0  2.391213 -1.134149 -1.061005  3.208220 -0.057589  0.591722  \n",
       "1  1.400879  0.440617  0.250877  0.920801  0.138718 -0.052341  \n",
       "2  1.164689 -2.721737 -1.270373  2.793598  0.333958  0.790519  \n",
       "3  0.756997  0.983355  0.660556 -0.030405  0.180313 -0.427872  \n",
       "4  1.381274 -1.549053 -2.936785  2.497881  0.276085  0.167375  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.read_csv('X_test.csv', float_precision='high').drop('id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_ = evclf.predict(X_final)\n",
    "\n",
    "#y_final_pred['y'] = model.predict(X_final).argmax(axis=1)\n",
    "#y_final_pred.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_pred = pd.read_csv('sample.csv')\n",
    "y_final_pred['y'] = pd.DataFrame(y_pred_) \n",
    "y_final_pred.to_csv('bagging_voting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('pred_nn.gz', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
